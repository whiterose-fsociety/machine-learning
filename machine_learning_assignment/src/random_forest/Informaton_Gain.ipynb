{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:lightgreen\">Information Gain</h2>\n",
    "\n",
    "<h3> Collection of methods that handle different scenarios for dirrent representations of data </h3>\n",
    "\n",
    "<h4 style=\"color:lightblue\"> #TODO - Sanity Checks </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:lightgreen\">Entropy methods</h3>\n",
    "<h4 style=\"color:lightblue\">Free to edit </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:pink\">Inputs</h3>\n",
    "<h4>Option of entering just dataframe or both dataframe and feature name(s)</h4>\n",
    "<h5>Pandas Dataframe</h5>\n",
    "<h5>Feature/s</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:lightblue\">One line implementations of entropy</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lazy_entropy(dataset,column):\n",
    "\tentropy = abs(sum([(x/sum(list(dataset.iloc[:,column].value_counts())))*np.log2(x/sum(list(dataset.iloc[:,column].value_counts()))) for x in list(dataset.iloc[:,column].value_counts())]))\n",
    "\treturn entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Second implementation\n",
    "def lazy_entropy(dataset,column):\n",
    "\tentropy = abs(sum([(x/sum(list(dataset.iloc[:,column].value_counts())))*np.log2(x/sum(list(dataset.iloc[:,column].value_counts()))) for x in list(dataset.iloc[:,column].value_counts())]))\n",
    "\treturn entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: Column values of a pandas Dataframe\n",
    "def entropy_feature(dataset,column):\n",
    "  unique_values = list(dataset[column].value_counts())\n",
    "  probs = [x/sum(unique_values) for x in unique_values]\n",
    "  # [-0.6428571428571429, -0.35714285714285715]\n",
    "  entropy = sum([prob*np.log2(prob) for prob in probs])\n",
    "  return abs(entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Pass in dataset, assumes that last column is the target class </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(dataset):\n",
    "  unique_values =  list(dataset.iloc[:,-1].value_counts())\n",
    "  probs = [x/sum(unique_values) for x in unique_values]\n",
    "  entropy = sum([prob*np.log2(prob) for prob in probs])\n",
    "  return abs(entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:pink\">Information Gain Methods </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gain_feature(dataset,feature):\n",
    "\t# Original dataset\n",
    "\tunique_values = list(dataset[feature].value_counts())\n",
    "\t# Names of the features\n",
    "\tunique_index = dataset[feature].value_counts().index.tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\tinfo_gain = 0\n",
    "\tdata_entropy = entropy(dataset)\n",
    "\tdata_size = dataset.shape[0]\n",
    "\n",
    "\tentropies = []\n",
    "\t# Finds Entropies and returns list of entropy and size\n",
    "\tfor unique_feature in unique_index:\n",
    "\t\tfilt = dataset[feature]\t== unique_feature\n",
    "\t\t# Create new dataset according to feature split\n",
    "\t\tfeature_dataset = dataset[filt]\t\n",
    "\t\t# [([entropies,size],[])]\n",
    "\t\tentropies.append((entropy(feature_dataset),feature_dataset.shape[0]))\n",
    "\n",
    "\n",
    "\tbranch_entropy = sum([ data[0] * data[1] for data in entropies])\n",
    "\tinfo_gain = data_entropy - branch_entropy/data_size\n",
    "\t\n",
    "\treturn info_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gains_features(dataset,features):\n",
    "\tinfo_gains = {}\n",
    "\tfeature_size = len(features) - 1\n",
    "\tfor feature,size in zip(features,range(feature_size)):\n",
    "\t\tinfo_gains[size] = info_gain_feature(dataset,feature)\n",
    "\treturn info_gains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:lightgreen\"> Second Implementation </h4>\n",
    "<p><strong>Returns a dictionary of information gains for each feature. Where key = column index in the table and value = information gain </strong></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample return  = {0: 0.24674981977443899, 1: 0.029222565658954647, 2: 0.15183550136234147, 3: 0.048127030408269267}\n",
    "def info_gains(dataset):\n",
    "\tcols = dataset.shape[1]\n",
    "\tinfo_gains = {}\n",
    "\tfor col in range(cols-1):\n",
    "\t\tunique_values = list(dataset.iloc[:,col].value_counts())\n",
    "\t\tunique_index = dataset.iloc[:,col].value_counts().index.tolist()\n",
    "\n",
    "\t\tinfo_gain = 0\n",
    "\t\tdata_entropy = entropy(dataset)\n",
    "\t\tdata_size = dataset.shape[0]\n",
    "\n",
    "\t\tentropies = []\n",
    "\n",
    "\t\tfor unique_feature in unique_index:\n",
    "\t\t\tfilt = dataset.iloc[:,col] == unique_feature\n",
    "\t\t\tfeature_dataset = dataset[filt]\n",
    "\t\t\tentropies.append((entropy(feature_dataset),feature_dataset.shape[0]))\n",
    "\n",
    "\t\tbranch_entropy = sum([ data[0] * data[1] for data in entropies])\n",
    "\t\tinfo_gain = data_entropy - branch_entropy/data_size\t\t\n",
    "\n",
    "\t\t# info_gains.append((info_gain,col))\n",
    "\t\tinfo_gains[col] = info_gain\n",
    "\treturn info_gains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:lightgray\">Find Highest Information Gain </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return feature column with highest gain\n",
    "def best_attribute(gains):\n",
    "\tx  = []\n",
    "\tfor gain in gains.values():\n",
    "\t\tx.append(gain)\n",
    "\tm = max(x)\n",
    "\tindex = list(gains.keys())[list(gains.values()).index(m)]\n",
    "\treturn index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:lightgreen\"> Run Method </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:lightblue\">Example with Feature Names given </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Column: Information  {0: 0.24674981977443899, 1: 0.029222565658954647, 2: 0.15183550136234147, 3: 0.048127030408269267}\n",
      "\n",
      "Feature Column Index 0\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"tennis.csv\",header=None,names=[\"Outlook\",\"Temperature\",\"Humidity\",\"Windy\",\"Play\"])\n",
    "features=[\"Outlook\",\"Temperature\",\"Humidity\",\"Windy\",\"Play\"]\n",
    "gains = info_gains_features(dataset,features)\n",
    "print(\"Feature Column: Information \",gains) # Dictionary\n",
    "print()\n",
    "print(\"Feature Column Index\" ,best_attribute(gains))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:lightgreen\">Example with only dataset given </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Column: Information  {0: 0.24674981977443899, 1: 0.029222565658954647, 2: 0.15183550136234147, 3: 0.048127030408269267}\n",
      "\n",
      "Feature Column Index 0\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"tennis.csv\",header=None,names=[\"Outlook\",\"Temperature\",\"Humidity\",\"Windy\",\"Play\"])\n",
    "gains = info_gains(dataset)\n",
    "print(\"Feature Column: Information \",gains) # Dictionary\n",
    "print()\n",
    "print(\"Feature Column Index\" ,best_attribute(gains))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
